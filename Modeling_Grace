#FINAL_models_Nov23

# final models
# Model list:
# 1. lasso - cv
# 2. ridge - cv
# 3. tree - cv
# 4. ranfor 

load("/project/msca/capstone3/patient_matrix_final.RData")

set.seed(10)
train <- sample(1:nrow(patient_matrix),floor(0.6*nrow(patient_matrix)))
training.set <- patient_matrix[train,]
totalvalidation.set<-patient_matrix[-train,]
set.seed(10)
invalidation<-sample(1:nrow(totalvalidation.set),floor(0.5*nrow(totalvalidation.set)))
testing.set<-totalvalidation.set[invalidation,]
validation.set<-totalvalidation.set[-invalidation,]

ptm1 <- proc.time()

x_train <- model.matrix(y2_charges~.,training.set[,-1])
y_train <- training.set$y2_charges
x_val <- model.matrix(y2_charges~.,validation.set[,-1])
y_val <- validation.set$y2_charges

# ridge regression
library(glmnet)
grid <- 10^seq(3,-3,length=10) # medium grid
grid2 <- 10^seq(0,6,length=10) #large-numbered grid
ptm2 <- proc.time()
ridge.mod <- glmnet(x_train,y_train,alpha=0,lambda=grid2) #31s runtime
proc.time() - ptm2 
ptm3 <- proc.time()
set.seed(10)
cv.ridge <- cv.glmnet(x_train,y_train,lambda=grid2,alpha=0) #5.7-minute runtime
proc.time() - ptm3
plot(cv.ridge) # correct range used!
ridge.pred <- predict(ridge.mod,s=cv.ridge$lambda.min,exact=T,newx=x_val)
ridge.mse <- mean((ridge.pred-y_val)^2)
ridge.rmse <- sqrt(mean((ridge.pred-y_val)^2))
ridge.mae <- mean(abs(ridge.pred-y_val))
plot(ridge.pred,y_val,main="Ridge Predicted Values v. True Values")
abline(0,1)
r2.ridge <- summary(lm(ridge.pred~y_val))$r.squared

# lasso
lasso.mod <- glmnet(x_train,y_train,alpha=1,lambda=grid2) #25-sec runtime
ptm4 <- proc.time()
set.seed(10)
cv.lasso  <- cv.glmnet(x_train,y_train,lambda=grid2,alpha=1) #5.6-min runtime
proc.time() - ptm4
plot(cv.lasso)
lasso.pred <- predict(lasso.mod,s=cv.lasso$lambda.min, newx=x_val) 
lasso.mse <- mean((lasso.pred-y_val)^2)
lasso.rmse <- sqrt(mean((lasso.pred-y_val)^2))
lasso.mae <- mean(abs(lasso.pred-y_val))
plot(lasso.pred,y_val,main="Lasso Predicted Values v. True Values")
abline(0,1)
r2.lasso <- summary(lm(lasso.pred~y_val))$r.squared
r2.lasso


# investigate the lasso coefficients that were NOT turned to 0.
lasso_coeffs <- predict(lasso.mod,s=cv.lasso$lambda.min,type="coefficients")
length(which(lasso_coeffs!=0)) #26
#dimnames(lasso_coeffs)[[1]][which(lasso_coeffs!=0)]
# investigate the ridge coefficients that were NOT turned to 0.
ridge_coeffs <- predict(ridge.mod,s=cv.ridge$lambda.min,type="coefficients")
#dimnames(ridge_coeffs)[[1]][which(ridge_coeffs!=0)] #only 2 predictors included!
length(dimnames(ridge_coeffs)[[1]][which(ridge_coeffs!=0)])
length(dimnames(ridge_coeffs)[[1]])

# regression tree
ptm7 <- proc.time()
library(tree)
regression.tree <- tree(y2_charges~.,training.set[,-1]) #really fast!
summary(regression.tree) #only used 2 variables! labfreq and y1_charges actually used in treebuilding. Why?
cv.regression.tree <- cv.tree(regression.tree) #took a couple minutes!
proc.time() - ptm7
#plot error rate as function of both size and k
plot(cv.regression.tree$size,cv.regression.tree$dev, type="b",xlab="Tree Size",ylab="Deviance",main="Cross-validation of Regression Tree Shows Tree Size Associated with Lowest Deviance") #deviance is higher with smaller trees; we do not prune.
plot(cv.regression.tree$k,cv.regression.tree$dev, type="b") 
plot(regression.tree,main="Regression Tree Includes 2 Predictor Variables") #unpruned tree tree
text(regression.tree)
tree.pred <- predict(regression.tree,newdata=validation.set[,-1])
tree.mse <- mean((tree.pred-y_val)^2) #MSE
tree.rmse <- sqrt(mean((tree.pred-y_val)^2)) # RMSE says we're on average $37,535 off from our predictions (I think)
tree.mae <- mean(abs(tree.pred-y_val))
plot(tree.pred,y_val,main="Regression Tree, Predicted Values v. True Values")
abline(0,1)

save.image(file="/project/msca/capstone3/Grace_final_models2.RData")

# build a random forest based on the variables that were not shrunk to 0 by lasso
library(randomForest)
ptm <- proc.time()
set.seed(10)
ranforALL <- randomForest(training.set[-c(1,10)],y=training.set$y2_charges,ntree=50,importance=T,do.trace=T)
proc.time() - ptm # user=37716.020, system=3.916,elapsed=37717.933 (10.4 hour runtime for 50 trees)
#save(ranforALL,file="/project/msca/capstone3/ranforALL.RData")
ranforALL.pred <- predict(ranforALL,newdata=validation.set[,-1])
ranforALL.mse <- mean((ranforALL.pred-validation.set$y2_charges)^2)
ranforALL.rmse <- sqrt(mean((ranforALL.pred-validation.set$y2_charges)^2))
ranforALL.mae <- mean(abs(ranforALL.pred-validation.set$y2_charges))
#plot(importance(ranforALL))
ranfor.imp <- as.data.frame(importance(ranforALL))
names(ranfor.imp)<- c("PercentIncMSE","IncNodePurity")
head(ranfor.imp[order(ranfor.imp$PercentIncMSE,decreasing=T),],50)
# library(randomForest)
# ptm <- proc.time()
# set.seed(10)
# ranforALL <- randomForest(training.set[-c(1,10)],y=training.set$y2_charges,ntree=50,importance=T,do.trace=T)
# proc.time() - ptm 
# ranforALL.pred <- predict(ranforALL,newdata=validation.set[,-1])
# ranforALL.mse <- mean((ranforALL.pred-validation.set$y2_charges)^2)
# ranforALL.rmse <- sqrt(mean((ranforALL.pred-validation.set$y2_charges)^2))
# ranforALL.mae <- mean(abs(ranforALL.pred-validation.set$y2_charges))
#plot(importance(ranforALL))
save.image(file="/project/msca/capstone3/Grace_final_models3.RData")

save.image(file="/project/msca/capstone3/Grace_final_models2.RData")


#Random Forest
library(randomForest)
ptm11 <- proc.time()
set.seed(10)
# Models run total
mse <- c(ridge=ridge.mse,lasso=lasso.mse,tree=tree.mse,ranfor=ranfor.lasso.mse,ranfor2=ranfor.lasso.mse2)
mae <- c(ridge=ridge.mae,lasso=lasso.mae,tree=tree.mae,ranfor=ranfor.lasso.mae,ranfor2=ranfor.lasso.mae2)
rmse <- c(ridge=ridge.rmse,lasso=lasso.rmse,tree=tree.rmse,ranfor=ranfor.lasso.rmse,ranfor2=ranfor.lasso.rmse2)


#plot Predicted Values v. True Values
par(mfrow=c(2,3))
plot(ridge.pred,y_val,main="Ridge",xlab="True Charge Value ($)",ylab="Predicted Charges Value ($)")
#text(100000,1200000,labels=paste("R^2=",round(r2.ridge,3)))
abline(0,1,col="red",cex=2)
plot(lasso.pred,y_val,main="Lasso",xlab="True Charge Value ($)",ylab="Predicted Charges Value ($)")
#text(200000,1200000,labels=paste("R^2=",round(r2.lasso,3)))
abline(0,1,col="red",cex=2)
plot(tree.pred,y_val,main="Regression Tree",xlab="True Charge Value ($)",ylab="Predicted Charges Value ($)")
#text(300000,1200000,labels=paste("R^2=",round(r2.tree,3)))
abline(0,1,col="red",cex=2)
plot(ranforALL.pred ,y_val,xlab="True Charge Value ($)",ylab="Predicted Charges Value ($)")
#text(300000,1200000,labels=paste("R^2=",round(r2.ranfor,3)))
abline(0,1,col="red",cex=2)
plot(ranfor.pred2 ,y_val,main="Random Forest",xlab="True Charge Value ($)",ylab="Predicted Charges Value ($)")
#text(300000,1200000,labels=paste("R^2=",round(r2.ranfor2,3)))
abline(0,1,col="red",cex=2)
par(mfrow=c(1,1))

# predict on final testing.set
ranfor.test.pred <- predict(ranforALL,newdata=testing.set[,-1])
ranfor.test.mse <- mean((ranfor.test.pred-testing.set$y2_charges)^2)
ranfor.test.rmse <- sqrt(mean((ranfor.test.pred-testing.set$y2_charges)^2))
ranfor.test.mae <- mean(abs(ranfor.test.pred-testing.set$y2_charges))
ranfor.test.mae2 <- mean((ranfor.test.pred-testing.set$y2_charges))



# plot the difference in cost buckets
nrow(testing.set)/4 #1719.25
low <- testing.set$y2_charges[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[1:1720])]
med <- testing.set$y2_charges[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[1721:3439])]
high <- testing.set$y2_charges[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[3440:5158])]
vhi <- testing.set$y2_charges[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[5159:nrow(testing.set)])]
mae_low <- mean(abs(ranfor.test.pred[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[1:1720])]-testing.set$y2_charges[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[1:1720])]))
mae_med <- mean(abs(ranfor.test.pred[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[1721:3439])]-testing.set$y2_charges[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[1721:3439])]))
mae_hi <- mean(abs(ranfor.test.pred[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[3440:5158])]-testing.set$y2_charges[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[3440:5158])]))
mae_vhi <- mean(abs(ranfor.test.pred[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[5159:nrow(testing.set)])]-testing.set$y2_charges[which(testing.set$y2_charges %in% sort(testing.set$y2_charges)[5159:nrow(testing.set)])]))
ranFor_mae <- c(mae_low,mae_med,mae_hi,mae_vhi)
max(low) #1405
min(med) #1407
max(med) #4945
min(high) #4955
max(high) #14289
min(vhi) #14296

# plot MAE for different cost buckets
plot(ranFor_mae,type="l",col=1,ylim=c(0,35000),lty=1,xaxt="n",main="Mean Absolute Error of Predicted costs for Patients Across 4 Cost Buckets",xlab="Cost Bucket",ylab="Mean Absolute Error (MAE)")
axis(1,at=1:4,labels=c("True Cost < $1406","$1406 < True Cost =< $4950","$4950 <True Cost< $14,293","True Cost >$14,293"))
vals1 <- c(1.25,2,2.75,3.5)
text(x=vals1,y= c(2000+ranFor_mae[1:3],ranFor_mae[4]), labels=paste("$",as.character(round(ranFor_mae,digits=0))))



#text(x=vals,y= 1000+mae[c(4,7,3,2,1,5,6)], labels=as.character(round(mae[c(4,7,3,2,1,5,6)],digits=0)))
# plot MAE across models
mae <- c(ranfor=ranforALL.mae, lasso=lasso.mae,tree=tree.mae,ridge=ridge.mae,lm=18017.47,lm_log=18951.8)
models=c("Random Forest","Lasso","Tree","Ridge","Linear Regression","Log-transformed Linear")
barplot(mae[order(mae)],width=1,names.arg=models,ylim=c(0,21000),ylab="Mean Absolute Error (MAE), in Dollars",main="Mean Absolute Error of Predicted Cost Values from True Cost Values")
grid()
vals <- seq(0.5,8,1.25)
text(x=vals,y= 1000+mae, labels=paste("$",as.character(round(mae,digits=0))))

# plot MSE across models
mse <- c(ranfor8=1376543417,lasso=1457240037,tree=1482669132,ranfor25=1507159647,ridge=1640072495,lm=1751369515,lm_log=158419270358)
models=c("Random Forest, 8 ","Lasso","Tree","Random Forest, 25","Ridge","Linear Regression","Log-transformed Linear")
barplot(mse[order(mse)],width=1,names.arg=models,ylim=c(0,1957240037),ylab="Mean Squared Error (MSE)",main="Mean Squared Error of Predicted Cost Values from True Cost Values")
grid()
vals <- seq(0.5,8,1.25)
text(x=vals,y= c(100000000+mse[1:6],100000000+mse[6]), labels=paste("$",as.character(round(mse,digits=0))))

proc.time() - ptm1

save.image(file="/project/msca/capstone3/Grace_final_models2.RData")
load("/project/msca/capstone3/Grace_final_models2.RData")
