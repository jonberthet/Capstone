library(plyr)
library(caret)
library(e1071)
library(kernlab)
load("/project/msca/capstone3/patient_matrix2_final.RData")
load("/project/msca/capstone3/Octoberfinalmodels.RData")
#Build SVM
load("/project/msca/capstone3/datasplits2.RData")
trainingsetsvm<-training.set
validationsetsvm<-validation.set
trainingsetsvm$patient_id<-NULL
trainingsetsvm$y2_charges<-NULL
validationsetsvm$patient_id<-NULL
validationsetsvm$y2_charges<-NULL
trainingsetsvm$label<-as.integer(trainingsetsvm$label)
validationsetsvm$label<-as.integer(validationsetsvm$label)
ptm<-proc.time()
svmmulti<-ksvm(label~., data=trainingsetsvm, type="C-svc", kernel="rbfdot", cross=10, C=10, prob.model=F)
proc.time() - ptm
svmmulti


#Predict 

predclass<-predict(svmmulti)


training.set1<-cbind(predclass, training.set)
Hightrain<-subset(training.set1, predclass=='2')
Lowtrain<-subset(training.set1, predclass=='1')
save(predclass, Hightrain, Lowtrain,  file="/project/msca/capstone3/katiepredclass.RData")


#Grace's classification data
load("/project/msca/capstone3/tree_predclass.RData")
training.set2<-cbind(tree.predclass, training.set)
HightrainG<-subset(training.set2, tree.predclass=='2')
LowtrainG<-subset(training.set2, tree.predclass=='1')

#Lowtrain first
hist(training.set$y2_charges)

Lowtrainlm<-Lowtrain
Lowtrainlm$patient_id<-NULL
Lowtrainlm$predclass<-NULL

x_train<-model.matrix(y2_charges~.,Lowtrainlm)
y_train <- Lowtrainlm$y2_charges
zerovariance<-nearZeroVar(x_train, saveMetrics=TRUE)
nrow(zerovariance[zerovariance[,"zeroVar"]=="TRUE",]) #697 variables removed
x_train<-x_train[,zerovariance$zeroVar==FALSE]
ncol(x_train)
dfCorr<-cor(x_train) #build correlation matrix
highCorr<-findCorrelation(dfCorr, 0.7) #find all pairwise correlations greater than 0.7
x_train<-x_train[,-highCorr] #remove highly correlated predictors from training set

#There were a total of 249 variables removed that were highly correlated.  3337 variables remain.



#Build benchmark linear regression from reduced data and look at residuals to determine if further transformations are needed
fulllm<-lm(y_train~x_train)
summary(fulllm)#Multiple R-squared:  0.719
fulllm.MSE <- mean((fulllm$fitted.values - y_train)^2)
fulllm.MSE
plot(fulllm)

#Predict on validate set

pred<-predict(fulllm, newdata=validation.set)
lmRMSE<-sqrt(mean((pred- validation.set$y2_charges)^2))
lmRMSE #58167.2
lmMAE<-mean(abs(pred-validation.set$y2_charges))
lmMAE #21732.51


#Hightrain next
#hist(training.set$y2_charges)

Hightrainlm<-Hightrain
Hightrainlm$patient_id<-NULL
Hightrainlm$predclass<-NULL

x_trainH<-model.matrix(y2_charges~.,Hightrainlm)
y_trainH <- Hightrainlm$y2_charges
zerovariance<-nearZeroVar(x_trainH, saveMetrics=TRUE)
nrow(zerovariance[zerovariance[,"zeroVar"]=="TRUE",]) # 3913variables removed
x_trainH<-x_trainH[,zerovariance$zeroVar==FALSE]
ncol(x_trainH)
dfCorr<-cor(x_trainH) #build correlation matrix
highCorr<-findCorrelation(dfCorr, 0.7) #find all pairwise correlations greater than 0.7
x_trainH<-x_trainH[,-highCorr] #remove highly correlated predictors from training set

#There were a total of  3881 variables removed that were highly correlated.   402 variables remain.



#Build benchmark linear regression from reduced data and look at residuals to determine if further transformations are needed
fulllmH<-lm(y_trainH~x_trainH)
summary(fulllmH)#Multiple R-squared:   0.9708
fulllm.MSE.High <- mean((fulllmH$fitted.values - y_trainH)^2)
fulllm.MSE.High
plot(fulllmH)

#Predict on validate set

predH<-predict(fulllmH, newdata=validation.set)
lmRMSE.High<-sqrt(mean((predH- validation.set$y2_charges)^2))
lmRMSE.High #381149.2
lmMAE.High<-mean(abs(predH-validation.set$y2_charges))
lmMAE.High #319021.4

#Grace's Hightrain next
#hist(training.set$y2_charges)

HightrainlmG<-HightrainG
HightrainlmG$patient_id<-NULL
HightrainlmG$predclass<-NULL

x_trainHG<-model.matrix(y2_charges~.,HightrainlmG)
y_trainHG <- HightrainlmG$y2_charges
zerovariance<-nearZeroVar(x_trainHG, saveMetrics=TRUE)
nrow(zerovariance[zerovariance[,"zeroVar"]=="TRUE",]) # 3903 variables removed
x_trainHG<-x_trainHG[,zerovariance$zeroVar==FALSE]
ncol(x_trainHG)
dfCorr<-cor(x_trainHG) #build correlation matrix
highCorr<-findCorrelation(dfCorr, 0.7) #find all pairwise correlations greater than 0.7
x_trainHG<-x_trainHG[,-highCorr] #remove highly correlated predictors from training set

#There were a total of 191 variables removed that were highly correlated.  190  variables remain.



#Build benchmark linear regression from reduced data and look at residuals to determine if further transformations are needed
fulllmHG<-lm(y_trainHG~x_trainHG)
summary(fulllmHG)#Multiple R-squared:   0.9772
fulllm.MSE.HighG <- mean((fulllmHG$fitted.values - y_trainHG)^2)
fulllm.MSE.HighG
plot(fulllmHG)

#Predict on validate set

predHG<-predict(fulllmHG, newdata=validation.set)
lmRMSE.HighG<-sqrt(mean((predHG- validation.set$y2_charges)^2))
lmRMSE.HighG #349453.5
lmMAE.HighG<-mean(abs(predHG-validation.set$y2_charges))
lmMAE.HighG #269575.4

#Grace's Lowtrain next
#hist(training.set$y2_charges)

LowtrainlmG<-LowtrainG
LowtrainlmG$patient_id<-NULL
LowtrainlmG$predclass<-NULL

x_trainLG<-model.matrix(y2_charges~.,LowtrainlmG)
y_trainLG <- LowtrainlmG$y2_charges
zerovariance<-nearZeroVar(x_trainLG, saveMetrics=TRUE)
nrow(zerovariance[zerovariance[,"zeroVar"]=="TRUE",]) #  705 variables removed
x_trainLG<-x_trainLG[,zerovariance$zeroVar==FALSE]
ncol(x_trainLG)
dfCorr<-cor(x_trainLG) #build correlation matrix
highCorr<-findCorrelation(dfCorr, 0.7) #find all pairwise correlations greater than 0.7
x_trainLG<-x_trainLG[,-highCorr] #remove highly correlated predictors from training set

#There were a total of 273 variables removed that were highly correlated.  3338  variables remain.



#Build benchmark linear regression from reduced data and look at residuals to determine if further transformations are needed
fulllmLG<-lm(y_trainLG~x_trainLG)
summary(fulllmLG)#Multiple R-squared:   
fulllm.MSE.LowG <- mean((fulllmLG$fitted.values - y_trainLG)^2)
fulllm.MSE.LowG
plot(fulllmLG)

#Predict on validate set

predLG<-predict(fulllmLG, newdata=validation.set)
lmRMSE.LowG<-sqrt(mean((predLG- validation.set$y2_charges)^2))
lmRMSE.LowG #
lmMAE.LowG<-mean(abs(predLG-validation.set$y2_charges))
lmMAE.LowG #


#Comparisons
lmRMSE.LowG
lmMAE.LowG
lmRMSE.HighG
lmMAE.HighG
lmMAE.LowG
lmRMSE
lmMAE
lmRMSE.High
lmMAE.High
